name: Selenium Test Pipeline

on:
  workflow_dispatch:
    inputs:
      selected_group:
        description: "Select the test group to run"
        required: true
        default: "all"
        type: choice
        options:
          - all
          - dataset_registration
          - dataset_physical
          - dataset_virtual
          - taskflows
          - end_to_end_sql
          - end_to_end_nas
          - end_to_end_s3

jobs:
  # Step 1: Test Data Check and Creation
  testDataCheckAndCreation:
    runs-on: windows-latest
    outputs:
      createTestData: ${{ steps.read-flag.outputs.createTestData }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Install YAML Dependencies
        run: pip install pyyaml

      - name: Read createTestData Flag (PowerShell)
        id: read-flag
        shell: pwsh
        run: |
          $jsonContent = python -c "import yaml, json; print(json.dumps(yaml.safe_load(open('config.yaml'))))"
          $config = $jsonContent | ConvertFrom-Json
          echo "createTestData=$($config.createTestData)" | Out-File -FilePath $env:GITHUB_ENV -Append

      - name: Show Flag Value
        run: echo "createTestData is ${{ env.createTestData }}"

      - name: Install Dependencies
        if: env.createTestData == 'true'
        run: pip install -r requirements.txt

      - name: Run Test Data Generation (If Flag is True)
        if: env.createTestData == 'true'
        working-directory: metadata_driven
        run: python TestDataGenerationViaMetadata.py

      - name: List Generated Files
        run: dir metadata_driven

      - name: Upload Generated Test Data
        uses: actions/upload-artifact@v4
        with:
          name: generated-trade-data
          path: metadata_driven/trade_data_with_line_numbers.csv

  # Step 2: Parent Job - Test Case Execution
  test_execution:
    needs: testDataCheckAndCreation
    if: ${{ github.event.inputs.selected_group != '' }}
    runs-on: windows-latest
    steps:
      - name: Test Execution Hub
        run: echo "Starting test execution parent job..."

  # Step 2.1: Dataset Registration (Organizational Layer)
  testCaseExecution_dataset_registration:
    needs: [ testDataCheckAndCreation, test_execution ]
    if: ${{ github.event.inputs.selected_group == 'dataset_registration' || github.event.inputs.selected_group == 'all' }}
    runs-on: windows-latest
    steps:
      - name: Note
        run: echo "MARKER=-m 'physical or virtual'" | Out-File -FilePath $env:GITHUB_ENV -Append

      - name: Run Registration Dataset Tests
        run: pytest tests/ $MARKER --html=reports/data_registration_report.html --self-contained-html

  # Step 2.1.1: Physical Dataset Test Execution
  testCaseExecution_dataset_physical:
    needs: [ testDataCheckAndCreation, test_execution, testCaseExecution_dataset_registration ]
    if: ${{ github.event.inputs.selected_group == 'dataset_physical' || github.event.inputs.selected_group == 'dataset_registration' || github.event.inputs.selected_group == 'all' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Set Marker for Physical Tests
        run: echo "MARKER=-m 'physical'" >> $GITHUB_ENV

      - name: Run Physical Dataset Tests
        run: pytest tests/ $MARKER --html=reports/physical_report.html --self-contained-html

      - name: Upload Physical Dataset Report
        uses: actions/upload-artifact@v4
        with:
          name: physical-report
          path: reports/physical_report.html

  # Step 2.1.2: Virtual Dataset Test Execution
  testCaseExecution_dataset_virtual:
    needs: [ testDataCheckAndCreation, test_execution, testCaseExecution_dataset_registration ]
    if: ${{ github.event.inputs.selected_group == 'dataset_virtual' || github.event.inputs.selected_group == 'dataset_registration' || github.event.inputs.selected_group == 'all' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Set Marker for Virtual Tests
        run: echo "MARKER=-m 'virtual'" >> $GITHUB_ENV

      - name: Run Virtual Dataset Tests
        run: pytest tests/ $MARKER --html=reports/virtual_report.html --self-contained-html

      - name: Upload Virtual Dataset Report
        uses: actions/upload-artifact@v4
        with:
          name: virtual-report
          path: reports/virtual_report.html

  # Step 3: Data Reconciliation
  dataReconciliation:
    needs: testCaseExecution
    runs-on: windows-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Run Data Reconciliation
        run: echo "Tests completed. You can add real data reconciliation logic here."
